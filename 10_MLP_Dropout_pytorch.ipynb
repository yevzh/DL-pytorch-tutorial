{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout丢弃法缓解过拟合(简洁实现)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import tarfile\n",
    "import time\n",
    "import json\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from collections import namedtuple\n",
    "\n",
    "from IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import init\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchtext\n",
    "import torchtext.vocab as Vocab\n",
    "import numpy as np\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_fashion_mnist(batch_size, resize=None, root='data/FashionMNIST'):\n",
    "    \"\"\"Download the fashion mnist dataset and then load into memory.\"\"\"\n",
    "    trans = []\n",
    "    if resize:\n",
    "        trans.append(torchvision.transforms.Resize(size=resize))\n",
    "    trans.append(torchvision.transforms.ToTensor())\n",
    "    \n",
    "    transform = torchvision.transforms.Compose(trans)\n",
    "    mnist_train = torchvision.datasets.FashionMNIST(root=root, train=True, download=True, transform=transform)\n",
    "    mnist_test = torchvision.datasets.FashionMNIST(root=root, train=False, download=True, transform=transform)\n",
    "    if sys.platform.startswith('win'):\n",
    "        num_workers = 0  # 0表示不用额外的进程来加速读取数据\n",
    "    else:\n",
    "        num_workers = 4\n",
    "    train_iter = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    test_iter = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "    return train_iter, test_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_iter, test_iter = load_data_fashion_mnist(batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义模型网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlattenLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FlattenLayer,self).__init__()\n",
    "    def forward(self,x):\n",
    "        return x.view(x.shape[0],-1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pytorch提供了自动的dropout层函数，在训练时启用，验证时不启用\n",
    "\n",
    "关于pytorch如何识别是否是训练集：在torchvision读取该数据库时，建立dataset的函数有bool型参数train\n",
    "\n",
    "所以当train_iter传入数据时判断为训练模式，test_iter传入数据时判断为测试模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs,num_hidden1,num_hidden2,num_outputs=784,512,256,10\n",
    "drop_prob1,drop_prob2=0.2,0.5\n",
    "\n",
    "net=nn.Sequential(\n",
    "    FlattenLayer(),\n",
    "    nn.Linear(num_inputs, num_hidden1),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(drop_prob1),\n",
    "    nn.Linear(num_hidden1, num_hidden2),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(drop_prob2),\n",
    "    nn.Linear(num_hidden2, num_outputs)\n",
    ")\n",
    "\n",
    "for param in net.parameters():\n",
    "    init.normal_(param,mean=0,std=0.01)\n",
    "    \n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.5)\n",
    "\n",
    "# 以下为计算测试集准确率\n",
    "def evaluate_accuracy(data_iter,net):\n",
    "    acc_sum, n=0.0, 0\n",
    "    for X,y in data_iter:\n",
    "        acc_sum+=(net(X).argmax(dim=1)==y).float().sum().item()  #注意这里是sum不是mean 之后会÷n\n",
    "        n+=y.shape[0]\n",
    "    return acc_sum / n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.0011, train acc 0.893, test acc 0.863\n",
      "epoch 2, loss 0.0011, train acc 0.897, test acc 0.859\n",
      "epoch 3, loss 0.0010, train acc 0.900, test acc 0.859\n",
      "epoch 4, loss 0.0010, train acc 0.904, test acc 0.835\n",
      "epoch 5, loss 0.0010, train acc 0.909, test acc 0.843\n",
      "epoch 6, loss 0.0009, train acc 0.908, test acc 0.874\n",
      "epoch 7, loss 0.0009, train acc 0.912, test acc 0.864\n",
      "epoch 8, loss 0.0009, train acc 0.912, test acc 0.882\n",
      "epoch 9, loss 0.0009, train acc 0.916, test acc 0.877\n",
      "epoch 10, loss 0.0008, train acc 0.918, test acc 0.850\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "def train(net,train_iter,test_iter,loss,num_epochs):\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum,train_acc_sum,n=0.0,0.0,0\n",
    "        \n",
    "        for X,y in train_iter:\n",
    "            y_hat=net(X)\n",
    "            l=loss(y_hat,y).sum()\n",
    "\n",
    "            # w和b梯度清零\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 计算loss函数梯度\n",
    "            l.backward()\n",
    "            \n",
    "            #梯度下降\n",
    "            optimizer.step()\n",
    "            \n",
    "            # loss和精确度加和\n",
    "            train_l_sum+=l.item()\n",
    "            train_acc_sum+=(y_hat.argmax(dim=1)==y).sum().item()\n",
    "            n+=y.shape[0]\n",
    "        \n",
    "        test_acc=evaluate_accuracy(test_iter,net)\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f' \n",
    "            % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc))\n",
    "train (net, train_iter, test_iter, loss, num_epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c9bb90c8c31d02c70dc2c25559c9d82f9e11e69c39856b10e40706be7daafd48"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
